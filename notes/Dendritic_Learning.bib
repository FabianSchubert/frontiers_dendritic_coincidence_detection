Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Guerguiev_2017,
abstract = {Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that a deep learning algorithm that utilizes multi- compartment neurons might help us to understand how the neocortex optimizes cost functions. Like neocortical pyramidal neurons, neurons in our model receive sensory information and higher- order feedback in electrotonically segregated compartments. Thanks to this segregation, neurons in different layers of the network can coordinate synaptic weight updates. As a result, the network learns to categorize images better than a single layer network. Furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful higher-order representationsâ€”the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons.},
archivePrefix = {arXiv},
arxivId = {1610.00161},
author = {Guerguiev, Jordan and Lillicrap, Timothy P. and Richards, Blake A.},
doi = {10.7554/eLife.22901},
eprint = {1610.00161},
file = {:home/fabian/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guerguiev, Lillicrap, Richards - 2017 - Towards deep learning with segregated dendrites.pdf:pdf},
issn = {2050084X},
journal = {eLife},
month = {dec},
pmid = {29205151},
publisher = {eLife Sciences Publications Ltd},
title = {{Towards deep learning with segregated dendrites}},
volume = {6},
year = {2017}
}
@article{Urbanczik_2014,
abstract = {Recent modeling of spike-timing-dependent plasticity indicates that plasticity involves as a third factor a local dendritic potential, besides pre- and postsynaptic firing times. We present a simple compartmental neuron model together with a non-Hebbian, biologically plausible learning rule for dendritic synapses where plasticity is modulated by these three factors. In functional terms, the rule seeks to minimize discrepancies between somatic firings and a local dendritic potential. Such prediction errors can arise in our model from stochastic fluctuations as well as from synaptic input, which directly targets the soma. Depending on the nature of this direct input, our plasticity rule subserves supervised or unsupervised learning. When a reward signal modulates the learning rate, reinforcement learning results. Hence a single plasticity rule supports diverse learning paradigms. {\textcopyright} 2014 Elsevier Inc.},
author = {Urbanczik, Robert and Senn, Walter},
doi = {10.1016/j.neuron.2013.11.030},
file = {:home/fabian/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Urbanczik, Senn - 2014 - Learning by the Dendritic Prediction of Somatic Spiking.pdf:pdf},
issn = {08966273},
journal = {Neuron},
month = {feb},
number = {3},
pages = {521--528},
pmid = {24507189},
publisher = {Elsevier},
title = {{Learning by the Dendritic Prediction of Somatic Spiking}},
url = {http://dx.},
volume = {81},
year = {2014}
}
@article{Schiess_2016,
abstract = {In the last decade dendrites of cortical neurons have been shown to nonlinearly combine synaptic inputs by evoking local dendritic spikes. It has been suggested that these nonlinearities raise the computational power of a single neuron, making it comparable to a 2-layer network of point neurons. But how these nonlinearities can be incorporated into the synaptic plasticity to optimally support learning remains unclear. We present a theoretically derived synaptic plasticity rule for supervised and reinforcement learning that depends on the timing of the presynaptic, the dendritic and the postsynaptic spikes. For supervised learning, the rule can be seen as a biological version of the classical error-backpropagation algorithm applied to the dendritic case. When modulated by a delayed reward signal, the same plasticity is shown to maximize the expected reward in reinforcement learning for various coding scenarios. Our framework makes specific experimental predictions and highlights the unique advantage of active dendrites for implementing powerful synaptic plasticity rules that have access to downstream information via backpropagation of action potentials.},
author = {Schiess, Mathieu and Urbanczik, Robert and Senn, Walter},
doi = {10.1371/journal.pcbi.1004638},
file = {:home/fabian/.var/app/com.elsevier.MendeleyDesktop/data/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schiess, Urbanczik, Senn - 2016 - Somato-dendritic Synaptic Plasticity and Error-backpropagation in Active Dendrites.pdf:pdf},
issn = {15537358},
journal = {PLoS Computational Biology},
keywords = {Action potentials,Dendritic structure,Membrane potential,Neuronal dendrites,Neuronal plasticity,Neurons,Synapses,Synaptic plasticity},
month = {feb},
number = {2},
pages = {1004638},
pmid = {26841235},
publisher = {Public Library of Science},
title = {{Somato-dendritic Synaptic Plasticity and Error-backpropagation in Active Dendrites}},
url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004638},
volume = {12},
year = {2016}
}
@article{Shai_2015,
author = {Shai, A S and Anastassiou, C A and Larkum, M E and Koch, C},
journal = {PLOS Computational Biology},
number = {3},
title = {{Physiology of Layer 5 Pyramidal Neurons in Mouse Primary Visual Cortex: Coincidence Detection through Bursting}},
volume = {11},
year = {2015}
}
